Phase: 5 - DCS Engine & Scan Results
Part: 5.1
Title: Data Models for DCS, Memory & AI
Depends On: 4.8-DCS-Foundation-Overview.md
Objective: To implement the robust, normalized three-tier SQLAlchemy data model architecture. This refactored design enforces data integrity at the database level, simplifies data management, and establishes a traceable foundation for all scan data, generated content, and future AI capabilities.
1. Core Principle: Normalized & Structured Data
We will avoid storing large, unstructured JSON blobs wherever possible. The product vision in the chunk files describes rich, relational data (e.g., a CTA links to a scan, which links to a project). A normalized schema is the only way to maintain data integrity, ensure query performance, and build a scalable system. This is an evolution of the simpler idea in Core-app-idea.md into a production-ready design.
2. Tier 1: CentralRawData Model
This model is the global, platform-wide cache for all raw third-party API data. Its purpose is to eliminate duplicate API calls.
File Location: backend/app/models/central_raw_data.py
File Content:
import uuid
from sqlalchemy import Column, String, Index
from sqlalchemy.dialects.postgresql import UUID, JSONB

from app.models.base import Base, BaseMixin

class CentralRawData(Base, BaseMixin):
    __tablename__ = 'central_raw_data'
    __table_args__ = (
        Index('ix_domain_data_type', 'domain', 'data_type'),
        Index('ix_url_data_type', 'url', 'data_type'),
    )

    domain = Column(String(255), nullable=False)
    url = Column(String(2048), nullable=True)
    data_type = Column(String(50), nullable=False) # e.g., 'KEYWORDS_DATAFORSEO', 'PAGESPEED_GOOGLE'
    source = Column(String(50), nullable=False)
    raw_data = Column(JSONB, nullable=False)
    checksum = Column(String(64), nullable=False, unique=True, index=True) # SHA-256 hash for deduplication

3. Audit and ScanResult Models
These models track the execution and high-level results of DCS scans.
File Location: backend/app/models/audit.py
File Content:

import enum
from sqlalchemy import Column, String, Enum as SQLEnum, ForeignKey, Integer, Text
from sqlalchemy.orm import relationship

from app.models.base import Base, BaseMixin

class AuditType(str, enum.Enum):
    QUICK_SCAN = "QUICK_SCAN"
    DEEP_SCAN = "DEEP_SCAN"

class AuditStatus(str, enum.Enum):
    PENDING = "PENDING"
    RUNNING = "RUNNING"
    COMPLETED = "COMPLETED"
    FAILED = "FAILED"

class Audit(Base, BaseMixin):
    __tablename__ = 'audits'

    project_id = Column(ForeignKey('projects.id', ondelete='CASCADE'), nullable=False)
    user_id = Column(ForeignKey('users.id'), nullable=False)
    
    audit_type = Column(SQLEnum(AuditType), nullable=False)
    status = Column(SQLEnum(AuditStatus), nullable=False, default=AuditStatus.PENDING)
    
    credits_consumed = Column(Integer, nullable=True)
    failure_reason = Column(Text, nullable=True)
    
    project = relationship('Project')
    user = relationship('User')
    scan_result = relationship('ScanResult', back_populates='audit', uselist=False, cascade='all, delete-orphan')

# --- Scan Result Model ---
class ScanResult(Base, BaseMixin):
    __tablename__ = 'scan_results'

    audit_id = Column(ForeignKey('audits.id', ondelete='CASCADE'), nullable=False)
    
    # High-level scores
    dcs_score = Column(Integer)
    ai_citation_score = Column(Integer)
    
    # Relationships to detailed, normalized data
    audit = relationship('Audit', back_populates='scan_result')
    generated_assets = relationship('GeneratedContentAsset', back_populates='scan_result', cascade='all, delete-orphan')

4. Tier 2: ProjectMemory & Generated Asset Models (Normalized)
This tier stores processed, actionable insights. The single ProjectMemory table acts as a hub, linking to new, dedicated tables for each type of generated content. This normalized approach is critical for querying and managing generated assets efficiently.
File Location: backend/app/models/project_memory.py
File Content:
from sqlalchemy import Column, String, ForeignKey, Text, Enum as SQLEnum
from sqlalchemy.orm import relationship
import enum

from app.models.base import Base, BaseMixin

class AssetType(str, enum.Enum):
    META_TAG = "META_TAG"
    ALT_TAG = "ALT_TAG"
    LLM_TXT = "LLM_TXT"
    ROBOTS_TXT = "ROBOTS_TXT"
    SCHEMA_MARKUP = "SCHEMA_MARKUP"
    CONTENT_BRIEF = "CONTENT_BRIEF"

class ProjectMemory(Base, BaseMixin):
    """A hub for a project's long-term intelligence, linking to specific data."""
    __tablename__ = 'project_memory'
    
    project_id = Column(ForeignKey('projects.id', ondelete='CASCADE'), nullable=False, unique=True)
    
    project = relationship('Project', back_populates='memory')
    # More direct relationships to structured memory data can be added here if needed

# --- Generated Content Asset Model ---
class GeneratedContentAsset(Base, BaseMixin):
    """Stores a specific piece of content generated by a CTA."""
    __tablename__ = 'generated_content_assets'
    
    project_id = Column(ForeignKey('projects.id', ondelete='CASCADE'), nullable=False)
    scan_result_id = Column(ForeignKey('scan_results.id', ondelete='CASCADE'), nullable=False)
    
    asset_type = Column(SQLEnum(AssetType), nullable=False)
    content = Column(Text, nullable=False) # Can be text, a file path, or JSON string
    
    # Link back to the scan that generated this asset
    scan_result = relationship('ScanResult', back_populates='generated_assets')
    project = relationship('Project')

(Note: A back-reference memory = relationship('ProjectMemory', ...) will be added to the Project model.)
5. Alembic Migration
After creating/updating these model files, we must generate a new migration to apply all the schema changes.
Execution Command (run in the backend directory):

alembic revision --autogenerate -m "Create DCS, audit, and normalized project memory models"
alembic upgrade head


