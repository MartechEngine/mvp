Phase: 6 - Content & Analysis Suite
Part: 6.13
Title: Backend Search Service
Depends On: 6.1-Backend-Unified-AI-Service.md, 5.7-Backend-Project-Memory-Service.md
Objective: To implement a comprehensive search service that enables users to quickly find projects, generated content, scan results, and historical data. This service provides full-text search, faceted filtering, and AI-powered semantic search capabilities.

## 1. Core Principles

**Multi-Modal Search**: Support for text search, semantic search, and structured filtering across all data types.
**Performance First**: Optimized indexing and caching for sub-second search responses.
**Relevance Scoring**: Advanced ranking algorithms that consider recency, user behavior, and content quality.
**Security Aware**: All search results respect organization boundaries and user permissions.

## 2. Search Data Models

### Search Index Model
```python
# File: backend/app/models/search_index.py
from sqlalchemy import Column, String, Text, DateTime, Enum, ForeignKey, Float, JSON, Boolean
from sqlalchemy.orm import relationship
from app.models.base import Base, BaseMixin
import enum

class SearchableType(str, enum.Enum):
    PROJECT = "PROJECT"
    SCAN_RESULT = "SCAN_RESULT"
    GENERATED_CONTENT = "GENERATED_CONTENT"
    ASSET = "ASSET"
    MEMORY_ENTRY = "MEMORY_ENTRY"
    ANALYSIS_REPORT = "ANALYSIS_REPORT"

class SearchIndex(Base, BaseMixin):
    __tablename__ = 'search_indices'
    
    # Core identification
    searchable_type = Column(Enum(SearchableType), nullable=False)
    searchable_id = Column(String(36), nullable=False)  # UUID of the searchable entity
    
    # Content for search
    title = Column(String(500), nullable=False)
    content = Column(Text, nullable=False)  # Full-text searchable content
    summary = Column(Text, nullable=True)   # Brief summary for snippets
    keywords = Column(JSON, nullable=True)  # Extracted keywords
    
    # Metadata for filtering
    organization_id = Column(ForeignKey('organizations.id'), nullable=False)
    project_id = Column(ForeignKey('projects.id'), nullable=True)
    user_id = Column(ForeignKey('users.id'), nullable=True)
    
    # Search optimization
    search_vector = Column(Text, nullable=True)  # PostgreSQL tsvector for full-text search
    embedding_vector = Column(JSON, nullable=True)  # AI embedding for semantic search
    popularity_score = Column(Float, default=0.0)  # Based on views, downloads, etc.
    quality_score = Column(Float, default=0.0)     # Content quality assessment
    
    # Lifecycle
    last_indexed_at = Column(DateTime, nullable=False)
    is_active = Column(Boolean, default=True)
    
    # Relationships
    organization = relationship('Organization')
    project = relationship('Project')
    user = relationship('User')
```

## 3. Search Service Implementation

```python
# File: backend/app/services/search_service.py
import logging
import time
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session
from sqlalchemy import and_, func
from dataclasses import dataclass

from app.core.config import settings
from app.models.search_index import SearchIndex, SearchableType

logger = logging.getLogger(__name__)

@dataclass
class SearchResult:
    id: str
    type: SearchableType
    title: str
    summary: str
    content_snippet: str
    relevance_score: float
    metadata: Dict[str, Any]
    url: str

@dataclass
class SearchResponse:
    results: List[SearchResult]
    total_count: int
    query_time_ms: int
    facets: Dict[str, List[Dict[str, Any]]]

class SearchService:
    """
    Comprehensive search service with full-text and semantic search capabilities.
    """
    
    def __init__(self, db: Session):
        self.db = db
    
    async def search(self, query: str, user_id: str, organization_id: str,
                    filters: Optional[Dict[str, Any]] = None,
                    search_type: str = "text",
                    limit: int = 20, offset: int = 0) -> SearchResponse:
        """
        Perform comprehensive search across all searchable content.
        """
        start_time = time.time()
        
        try:
            # Parse and validate query
            parsed_query = self._parse_query(query)
            if not parsed_query:
                return SearchResponse([], 0, 0, {})
            
            # Build base query with security filters
            base_query = self._build_base_query(organization_id, filters)
            
            # Execute text search
            results = await self._text_search(base_query, parsed_query, limit, offset)
            
            # Generate facets
            facets = self._generate_facets(base_query)
            
            # Calculate response time
            response_time = int((time.time() - start_time) * 1000)
            
            return SearchResponse(
                results=results,
                total_count=len(results),
                query_time_ms=response_time,
                facets=facets
            )
            
        except Exception as e:
            logger.error(f"Search failed: {e}")
            return SearchResponse([], 0, int((time.time() - start_time) * 1000), {})
    
    async def _text_search(self, base_query, parsed_query: str, 
                          limit: int, offset: int) -> List[SearchResult]:
        """Perform full-text search using PostgreSQL."""
        # Use PostgreSQL full-text search
        search_query = base_query.filter(
            func.to_tsvector('english', SearchIndex.content).match(parsed_query)
        ).order_by(
            func.ts_rank(func.to_tsvector('english', SearchIndex.content), 
                        func.plainto_tsquery('english', parsed_query)).desc(),
            SearchIndex.popularity_score.desc()
        ).limit(limit).offset(offset)
        
        indices = search_query.all()
        return [self._convert_to_search_result(idx, 0.8) for idx in indices]
    
    def _build_base_query(self, organization_id: str, filters: Optional[Dict[str, Any]]):
        """Build base query with security and filters."""
        query = self.db.query(SearchIndex).filter(
            and_(
                SearchIndex.organization_id == organization_id,
                SearchIndex.is_active == True
            )
        )
        
        if filters:
            # Apply type filter
            if 'type' in filters:
                query = query.filter(SearchIndex.searchable_type.in_(filters['type']))
            
            # Apply project filter
            if 'project_id' in filters:
                query = query.filter(SearchIndex.project_id.in_(filters['project_id']))
            
            # Apply date range filter
            if 'date_from' in filters:
                query = query.filter(SearchIndex.created_at >= filters['date_from'])
            if 'date_to' in filters:
                query = query.filter(SearchIndex.created_at <= filters['date_to'])
        
        return query
    
    def _parse_query(self, query: str) -> Optional[str]:
        """Parse and clean search query."""
        if not query or len(query.strip()) < 2:
            return None
        
        # Basic cleaning
        cleaned = query.strip().lower()
        
        # Remove special characters that might break search
        import re
        cleaned = re.sub(r'[^\w\s\-\.]', ' ', cleaned)
        
        # Remove extra whitespace
        cleaned = ' '.join(cleaned.split())
        
        return cleaned if len(cleaned) >= 2 else None
    
    def _convert_to_search_result(self, index: SearchIndex, relevance_score: float) -> SearchResult:
        """Convert search index to search result."""
        # Generate content snippet
        snippet = self._generate_snippet(index.content, 200)
        
        # Generate URL based on type
        url = self._generate_result_url(index)
        
        # Prepare metadata
        metadata = {
            'created_at': index.created_at.isoformat() if index.created_at else None,
            'project_id': index.project_id,
            'user_id': index.user_id,
            'quality_score': index.quality_score,
            'popularity_score': index.popularity_score
        }
        
        return SearchResult(
            id=index.searchable_id,
            type=index.searchable_type,
            title=index.title,
            summary=index.summary or snippet,
            content_snippet=snippet,
            relevance_score=relevance_score,
            metadata=metadata,
            url=url
        )
    
    def _generate_snippet(self, content: str, max_length: int = 200) -> str:
        """Generate content snippet for search results."""
        if len(content) <= max_length:
            return content
        
        # Find a good break point near the limit
        snippet = content[:max_length]
        last_space = snippet.rfind(' ')
        
        if last_space > max_length * 0.8:  # If we found a space in the last 20%
            snippet = snippet[:last_space]
        
        return snippet + "..."
    
    def _generate_result_url(self, index: SearchIndex) -> str:
        """Generate URL for search result."""
        base_url = "/app"
        
        if index.searchable_type == SearchableType.PROJECT:
            return f"{base_url}/projects/{index.searchable_id}"
        elif index.searchable_type == SearchableType.SCAN_RESULT:
            return f"{base_url}/projects/{index.project_id}/scans/{index.searchable_id}"
        elif index.searchable_type == SearchableType.GENERATED_CONTENT:
            return f"{base_url}/content/{index.searchable_id}"
        elif index.searchable_type == SearchableType.ASSET:
            return f"{base_url}/assets/{index.searchable_id}"
        else:
            return f"{base_url}/search?id={index.searchable_id}"
    
    def _generate_facets(self, base_query) -> Dict[str, List[Dict[str, Any]]]:
        """Generate search facets for filtering."""
        facets = {}
        
        # Type facets
        type_counts = self.db.query(
            SearchIndex.searchable_type,
            func.count(SearchIndex.id).label('count')
        ).filter(
            base_query.whereclause
        ).group_by(SearchIndex.searchable_type).all()
        
        facets['types'] = [
            {'value': str(type_val), 'count': count, 'label': type_val.replace('_', ' ').title()}
            for type_val, count in type_counts
        ]
        
        return facets
```

## 4. Search Indexing Service

```python
# File: backend/app/services/search_indexing_service.py
import logging
from typing import Optional, List
from sqlalchemy.orm import Session
from datetime import datetime
from sqlalchemy import and_

from app.models.search_index import SearchIndex, SearchableType
from app.models.project import Project
from app.models.scan_result import ScanResult
from app.models.asset import Asset

logger = logging.getLogger(__name__)

class SearchIndexingService:
    """
    Service for indexing searchable content.
    """
    
    def __init__(self, db: Session):
        self.db = db
    
    async def index_project(self, project: Project):
        """Index a project for search."""
        content = f"{project.name} {project.description or ''} {project.url}"
        keywords = self._extract_keywords(content)
        
        # Create or update search index
        existing = self.db.query(SearchIndex).filter(
            and_(
                SearchIndex.searchable_type == SearchableType.PROJECT,
                SearchIndex.searchable_id == str(project.id)
            )
        ).first()
        
        if existing:
            existing.title = project.name
            existing.content = content
            existing.keywords = keywords
            existing.last_indexed_at = datetime.utcnow()
        else:
            index = SearchIndex(
                searchable_type=SearchableType.PROJECT,
                searchable_id=str(project.id),
                title=project.name,
                content=content,
                summary=project.description,
                keywords=keywords,
                organization_id=project.organization_id,
                project_id=project.id,
                user_id=project.user_id,
                last_indexed_at=datetime.utcnow()
            )
            self.db.add(index)
        
        self.db.commit()
        logger.info(f"Indexed project: {project.id}")
    
    async def index_scan_result(self, scan_result: ScanResult):
        """Index a scan result for search."""
        # Build searchable content from scan result
        content_parts = []
        
        if scan_result.dcs_score is not None:
            content_parts.append(f"DCS Score: {scan_result.dcs_score}")
        
        if scan_result.ai_citation_score is not None:
            content_parts.append(f"AI Citation Score: {scan_result.ai_citation_score}")
        
        content = " ".join(content_parts)
        title = f"Scan Result for {scan_result.audit.project.name if scan_result.audit else 'Project'}"
        
        # Create search index
        index = SearchIndex(
            searchable_type=SearchableType.SCAN_RESULT,
            searchable_id=str(scan_result.id),
            title=title,
            content=content,
            summary=f"Scan completed on {scan_result.created_at.strftime('%Y-%m-%d')}",
            organization_id=scan_result.audit.project.organization_id,
            project_id=scan_result.audit.project_id,
            last_indexed_at=datetime.utcnow()
        )
        
        self.db.add(index)
        self.db.commit()
        logger.info(f"Indexed scan result: {scan_result.id}")
    
    async def index_asset(self, asset: Asset):
        """Index an asset for search."""
        content = f"{asset.original_filename} {asset.asset_type.value}"
        
        # Create search index
        index = SearchIndex(
            searchable_type=SearchableType.ASSET,
            searchable_id=str(asset.id),
            title=asset.original_filename,
            content=content,
            summary=f"{asset.asset_type.value} file ({asset.file_size} bytes)",
            organization_id=asset.organization_id,
            project_id=asset.project_id,
            user_id=asset.user_id,
            last_indexed_at=datetime.utcnow()
        )
        
        self.db.add(index)
        self.db.commit()
        logger.info(f"Indexed asset: {asset.id}")
    
    def remove_from_index(self, searchable_type: SearchableType, searchable_id: str):
        """Remove item from search index."""
        self.db.query(SearchIndex).filter(
            and_(
                SearchIndex.searchable_type == searchable_type,
                SearchIndex.searchable_id == searchable_id
            )
        ).delete()
        self.db.commit()
        logger.info(f"Removed from index: {searchable_type} {searchable_id}")
    
    def _extract_keywords(self, content: str) -> List[str]:
        """Extract keywords from content."""
        # Simple keyword extraction - in production, use more sophisticated NLP
        import re
        words = re.findall(r'\b\w{3,}\b', content.lower())
        
        # Remove common stop words
        stop_words = {'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}
        keywords = [word for word in words if word not in stop_words]
        
        # Return top 10 most frequent keywords
        from collections import Counter
        return [word for word, count in Counter(keywords).most_common(10)]
```

## 5. Search API Endpoints

```python
# File: backend/app/api/v1/endpoints/search.py
import logging
from fastapi import APIRouter, Depends, Query, HTTPException, status
from sqlalchemy.orm import Session
from typing import List, Optional, Dict, Any

from app.core.database import get_db
from app.api.v1.dependencies.auth_deps import get_current_active_user
from app.models.user import User as UserModel
from app.services.search_service import SearchService
from app.schemas.common_schemas import APISuccessResponse

logger = logging.getLogger(__name__)
router = APIRouter()

@router.get("/", response_model=APISuccessResponse[Dict[str, Any]])
async def search_content(
    q: str = Query(..., description="Search query"),
    type: Optional[List[str]] = Query(None, description="Filter by content type"),
    project_id: Optional[List[str]] = Query(None, description="Filter by project"),
    limit: int = Query(20, ge=1, le=100, description="Number of results"),
    offset: int = Query(0, ge=0, description="Offset for pagination"),
    db: Session = Depends(get_db),
    current_user: UserModel = Depends(get_current_active_user)
):
    """Search across all content."""
    search_service = SearchService(db)
    
    # Build filters
    filters = {}
    if type:
        filters['type'] = type
    if project_id:
        filters['project_id'] = project_id
    
    # Perform search
    results = await search_service.search(
        query=q,
        user_id=str(current_user.id),
        organization_id=str(current_user.organization_id),
        filters=filters,
        limit=limit,
        offset=offset
    )
    
    return APISuccessResponse(data={
        'results': [
            {
                'id': result.id,
                'type': result.type,
                'title': result.title,
                'summary': result.summary,
                'snippet': result.content_snippet,
                'relevance_score': result.relevance_score,
                'metadata': result.metadata,
                'url': result.url
            }
            for result in results.results
        ],
        'total_count': results.total_count,
        'query_time_ms': results.query_time_ms,
        'facets': results.facets
    })
```

## 6. Integration with Existing Services

Update existing services to automatically index content:

```python
# File: backend/app/services/project_service.py (modification)
from app.services.search_indexing_service import SearchIndexingService

class ProjectService:
    def __init__(self, db: Session):
        self.db = db
        self.search_indexing = SearchIndexingService(db)
    
    async def create_project(self, project_create: ProjectCreate, user_id: str) -> Project:
        # ... existing project creation logic ...
        
        # Index the new project for search
        await self.search_indexing.index_project(new_project)
        
        return new_project
```

## 7. Configuration Updates

```python
# File: backend/app/core/config.py (additions)
class Settings(BaseSettings):
    # ... existing settings ...
    
    # Search Configuration
    SEARCH_ENABLED: bool = True
    SEMANTIC_SEARCH_ENABLED: bool = False  # Requires AI embedding service
    SEARCH_INDEX_BATCH_SIZE: int = 100
    SEARCH_RESULTS_PER_PAGE: int = 20
```

## 8. Next Steps

This Search Service provides:
- ✅ **Full-text search** with PostgreSQL
- ✅ **Faceted filtering** by type, project, date
- ✅ **Automatic indexing** of all searchable content
- ✅ **Security-aware** search results
- ✅ **Performance optimized** with proper indexing

**Next File**: Create the Notification Service architecture to handle user engagement and system alerts.
