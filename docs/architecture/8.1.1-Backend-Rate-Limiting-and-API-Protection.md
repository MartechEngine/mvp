Phase: 8 - Operations and Compliance
Part: 8.1.1
Title: Backend Rate Limiting and API Protection
Depends On: 8.1-Phase-8-Operations-and-Compliance.md
Objective: To implement comprehensive rate limiting, API protection, and abuse prevention mechanisms that ensure system stability, prevent resource exhaustion, and protect against malicious attacks while maintaining excellent user experience for legitimate users.

## 1. Core Principles

**Multi-Layer Protection**: Rate limiting at multiple levels - global, per-user, per-endpoint, and per-IP.
**Adaptive Limits**: Different rate limits based on user subscription plans and endpoint criticality.
**Graceful Degradation**: Proper error responses with retry information when limits are exceeded.
**Monitoring & Alerting**: Real-time monitoring of rate limit violations and automatic threat detection.

## 2. Rate Limiting Strategy

### Tier-Based Rate Limiting
```python
# File: backend/app/core/rate_limits.py
from enum import Enum
from typing import Dict, NamedTuple

class RateLimitTier(str, Enum):
    FREE_TRIAL = "FREE_TRIAL"
    STARTER = "STARTER"
    PROFESSIONAL = "PROFESSIONAL"
    ENTERPRISE = "ENTERPRISE"
    ADMIN = "ADMIN"

class RateLimit(NamedTuple):
    requests_per_minute: int
    requests_per_hour: int
    requests_per_day: int
    burst_allowance: int  # Additional requests allowed in short bursts

# Global rate limits by subscription tier
TIER_RATE_LIMITS: Dict[RateLimitTier, RateLimit] = {
    RateLimitTier.FREE_TRIAL: RateLimit(
        requests_per_minute=30,
        requests_per_hour=500,
        requests_per_day=2000,
        burst_allowance=10
    ),
    RateLimitTier.STARTER: RateLimit(
        requests_per_minute=60,
        requests_per_hour=1500,
        requests_per_day=10000,
        burst_allowance=20
    ),
    RateLimitTier.PROFESSIONAL: RateLimit(
        requests_per_minute=120,
        requests_per_hour=5000,
        requests_per_day=50000,
        burst_allowance=50
    ),
    RateLimitTier.ENTERPRISE: RateLimit(
        requests_per_minute=300,
        requests_per_hour=15000,
        requests_per_day=200000,
        burst_allowance=100
    ),
    RateLimitTier.ADMIN: RateLimit(
        requests_per_minute=1000,
        requests_per_hour=50000,
        requests_per_day=1000000,
        burst_allowance=500
    )
}

# Endpoint-specific multipliers
ENDPOINT_MULTIPLIERS = {
    # Authentication endpoints - more restrictive
    "/api/v1/auth/login": 0.1,
    "/api/v1/auth/register": 0.05,
    "/api/v1/auth/reset-password": 0.02,
    
    # DCS scan endpoints - resource intensive
    "/api/v1/dcs/scan": 0.1,
    "/api/v1/dcs/bulk-scan": 0.02,
    
    # AI-powered endpoints - expensive
    "/api/v1/intelligence/content-generation": 0.2,
    "/api/v1/intelligence/keyword-analysis": 0.3,
    "/api/v1/intelligence/competitor-analysis": 0.2,
    
    # Standard CRUD operations
    "/api/v1/projects": 1.0,
    "/api/v1/user/profile": 2.0,
    "/api/v1/billing": 1.0,
    
    # High-frequency endpoints
    "/api/v1/health": 10.0,
    "/api/v1/progress": 5.0,
}
```

## 3. Rate Limiting Middleware

```python
# File: backend/app/middleware/rate_limiting.py
import time
import json
import logging
from typing import Optional, Tuple
from fastapi import Request, Response, HTTPException, status
from fastapi.responses import JSONResponse
import redis
from sqlalchemy.orm import Session

from app.core.config import settings
from app.core.database import get_db
from app.core.rate_limits import TIER_RATE_LIMITS, ENDPOINT_MULTIPLIERS, RateLimitTier
from app.models.user import User
from app.models.organization import Organization
from app.api.v1.dependencies.auth_deps import get_current_user_optional

logger = logging.getLogger(__name__)

class RateLimitMiddleware:
    """
    Comprehensive rate limiting middleware with Redis backend.
    """
    
    def __init__(self):
        self.redis_client = redis.Redis(
            host=settings.REDIS_HOST,
            port=settings.REDIS_PORT,
            password=settings.REDIS_PASSWORD,
            decode_responses=True
        )
    
    async def __call__(self, request: Request, call_next):
        # Skip rate limiting for health checks and internal endpoints
        if self._should_skip_rate_limiting(request):
            return await call_next(request)
        
        # Get user context
        user_context = await self._get_user_context(request)
        
        # Check rate limits
        rate_limit_result = await self._check_rate_limits(request, user_context)
        
        if not rate_limit_result.allowed:
            return self._create_rate_limit_response(rate_limit_result)
        
        # Process request
        response = await call_next(request)
        
        # Add rate limit headers
        self._add_rate_limit_headers(response, rate_limit_result)
        
        return response
    
    def _should_skip_rate_limiting(self, request: Request) -> bool:
        """Check if request should skip rate limiting."""
        skip_paths = [
            "/health",
            "/metrics",
            "/docs",
            "/openapi.json"
        ]
        return any(request.url.path.startswith(path) for path in skip_paths)
    
    async def _get_user_context(self, request: Request) -> dict:
        """Extract user context for rate limiting."""
        context = {
            'ip_address': self._get_client_ip(request),
            'user_id': None,
            'organization_id': None,
            'tier': RateLimitTier.FREE_TRIAL,
            'is_authenticated': False
        }
        
        try:
            # Try to get authenticated user
            db = next(get_db())
            user = await get_current_user_optional(request, db)
            
            if user:
                context.update({
                    'user_id': str(user.id),
                    'organization_id': str(user.organization_id) if user.organization_id else None,
                    'tier': self._get_user_tier(user),
                    'is_authenticated': True
                })
        except Exception as e:
            logger.debug(f"Could not get user context: {e}")
        
        return context
    
    def _get_client_ip(self, request: Request) -> str:
        """Extract client IP with proxy support."""
        # Check for forwarded headers (from load balancer/proxy)
        forwarded_for = request.headers.get('X-Forwarded-For')
        if forwarded_for:
            return forwarded_for.split(',')[0].strip()
        
        real_ip = request.headers.get('X-Real-IP')
        if real_ip:
            return real_ip
        
        return request.client.host if request.client else '127.0.0.1'
    
    def _get_user_tier(self, user: User) -> RateLimitTier:
        """Determine user's rate limit tier based on subscription."""
        if user.is_admin:
            return RateLimitTier.ADMIN
        
        # Check user's organization subscription
        if hasattr(user, 'organization') and user.organization:
            subscription = user.organization.active_subscription
            if subscription:
                plan_mapping = {
                    'starter': RateLimitTier.STARTER,
                    'professional': RateLimitTier.PROFESSIONAL,
                    'enterprise': RateLimitTier.ENTERPRISE
                }
                return plan_mapping.get(subscription.plan_id, RateLimitTier.FREE_TRIAL)
        
        return RateLimitTier.FREE_TRIAL
    
    async def _check_rate_limits(self, request: Request, user_context: dict) -> 'RateLimitResult':
        """Check all applicable rate limits."""
        endpoint = request.url.path
        method = request.method
        
        # Get rate limits for user's tier
        tier_limits = TIER_RATE_LIMITS[user_context['tier']]
        
        # Apply endpoint-specific multiplier
        endpoint_multiplier = ENDPOINT_MULTIPLIERS.get(endpoint, 1.0)
        
        # Calculate effective limits
        effective_limits = RateLimit(
            requests_per_minute=int(tier_limits.requests_per_minute * endpoint_multiplier),
            requests_per_hour=int(tier_limits.requests_per_hour * endpoint_multiplier),
            requests_per_day=int(tier_limits.requests_per_day * endpoint_multiplier),
            burst_allowance=int(tier_limits.burst_allowance * endpoint_multiplier)
        )
        
        # Check multiple rate limit windows
        checks = []
        
        # Per-user limits (if authenticated)
        if user_context['is_authenticated']:
            user_key = f"rate_limit:user:{user_context['user_id']}"
            checks.extend([
                (f"{user_key}:minute", effective_limits.requests_per_minute, 60),
                (f"{user_key}:hour", effective_limits.requests_per_hour, 3600),
                (f"{user_key}:day", effective_limits.requests_per_day, 86400),
            ])
        
        # Per-IP limits (always applied)
        ip_key = f"rate_limit:ip:{user_context['ip_address']}"
        ip_limits = TIER_RATE_LIMITS[RateLimitTier.FREE_TRIAL]  # IP limits use free tier
        checks.extend([
            (f"{ip_key}:minute", ip_limits.requests_per_minute, 60),
            (f"{ip_key}:hour", ip_limits.requests_per_hour, 3600),
        ])
        
        # Per-endpoint limits
        endpoint_key = f"rate_limit:endpoint:{endpoint.replace('/', '_')}"
        checks.append((f"{endpoint_key}:minute", effective_limits.requests_per_minute * 10, 60))
        
        # Check all limits
        for key, limit, window in checks:
            current_count = await self._increment_counter(key, window)
            
            if current_count > limit:
                return RateLimitResult(
                    allowed=False,
                    limit=limit,
                    remaining=0,
                    reset_time=int(time.time()) + window,
                    retry_after=window
                )
        
        # All checks passed
        return RateLimitResult(
            allowed=True,
            limit=effective_limits.requests_per_minute,
            remaining=max(0, effective_limits.requests_per_minute - current_count),
            reset_time=int(time.time()) + 60,
            retry_after=0
        )
    
    async def _increment_counter(self, key: str, window: int) -> int:
        """Increment rate limit counter using sliding window."""
        now = time.time()
        
        # Use Redis pipeline for atomic operations
        pipe = self.redis_client.pipeline()
        
        # Remove expired entries
        pipe.zremrangebyscore(key, 0, now - window)
        
        # Add current request
        pipe.zadd(key, {str(now): now})
        
        # Count current requests in window
        pipe.zcard(key)
        
        # Set expiration
        pipe.expire(key, window + 10)  # Add buffer for cleanup
        
        results = pipe.execute()
        return results[2]  # Count result
    
    def _create_rate_limit_response(self, result: 'RateLimitResult') -> JSONResponse:
        """Create rate limit exceeded response."""
        return JSONResponse(
            status_code=status.HTTP_429_TOO_MANY_REQUESTS,
            content={
                "error": "Rate limit exceeded",
                "message": f"Too many requests. Limit: {result.limit} per minute.",
                "retry_after": result.retry_after
            },
            headers={
                "X-RateLimit-Limit": str(result.limit),
                "X-RateLimit-Remaining": str(result.remaining),
                "X-RateLimit-Reset": str(result.reset_time),
                "Retry-After": str(result.retry_after)
            }
        )
    
    def _add_rate_limit_headers(self, response: Response, result: 'RateLimitResult'):
        """Add rate limit headers to successful responses."""
        response.headers["X-RateLimit-Limit"] = str(result.limit)
        response.headers["X-RateLimit-Remaining"] = str(result.remaining)
        response.headers["X-RateLimit-Reset"] = str(result.reset_time)

class RateLimitResult:
    """Rate limit check result."""
    
    def __init__(self, allowed: bool, limit: int, remaining: int, 
                 reset_time: int, retry_after: int):
        self.allowed = allowed
        self.limit = limit
        self.remaining = remaining
        self.reset_time = reset_time
        self.retry_after = retry_after
```

## 4. Advanced Protection Mechanisms

### DDoS Protection
```python
# File: backend/app/middleware/ddos_protection.py
import time
import logging
from collections import defaultdict, deque
from fastapi import Request, HTTPException, status

logger = logging.getLogger(__name__)

class DDoSProtectionMiddleware:
    """
    Advanced DDoS protection with pattern detection.
    """
    
    def __init__(self):
        self.request_patterns = defaultdict(lambda: deque(maxlen=1000))
        self.blocked_ips = {}
        self.suspicious_patterns = defaultdict(int)
    
    async def __call__(self, request: Request, call_next):
        client_ip = self._get_client_ip(request)
        
        # Check if IP is currently blocked
        if self._is_ip_blocked(client_ip):
            raise HTTPException(
                status_code=status.HTTP_429_TOO_MANY_REQUESTS,
                detail="IP temporarily blocked due to suspicious activity"
            )
        
        # Analyze request pattern
        if self._analyze_request_pattern(request, client_ip):
            self._block_ip(client_ip, duration=300)  # Block for 5 minutes
            raise HTTPException(
                status_code=status.HTTP_429_TOO_MANY_REQUESTS,
                detail="Suspicious activity detected. IP temporarily blocked."
            )
        
        return await call_next(request)
    
    def _analyze_request_pattern(self, request: Request, client_ip: str) -> bool:
        """Analyze request patterns for suspicious activity."""
        now = time.time()
        pattern_key = f"{client_ip}:{request.url.path}"
        
        # Add request to pattern tracking
        self.request_patterns[pattern_key].append(now)
        
        # Check for rapid-fire requests (more than 100 requests in 10 seconds)
        recent_requests = [t for t in self.request_patterns[pattern_key] if now - t < 10]
        if len(recent_requests) > 100:
            logger.warning(f"Rapid-fire requests detected from {client_ip}")
            return True
        
        # Check for distributed attack patterns
        total_recent = sum(
            len([t for t in times if now - t < 60])
            for times in self.request_patterns.values()
            if times and any(client_ip in key for key in self.request_patterns.keys())
        )
        
        if total_recent > 500:  # More than 500 requests per minute across all endpoints
            logger.warning(f"High-volume activity detected from {client_ip}")
            return True
        
        return False
    
    def _is_ip_blocked(self, ip: str) -> bool:
        """Check if IP is currently blocked."""
        if ip in self.blocked_ips:
            if time.time() < self.blocked_ips[ip]:
                return True
            else:
                del self.blocked_ips[ip]
        return False
    
    def _block_ip(self, ip: str, duration: int):
        """Block IP for specified duration."""
        self.blocked_ips[ip] = time.time() + duration
        logger.warning(f"Blocked IP {ip} for {duration} seconds")
    
    def _get_client_ip(self, request: Request) -> str:
        """Extract client IP."""
        forwarded_for = request.headers.get('X-Forwarded-For')
        if forwarded_for:
            return forwarded_for.split(',')[0].strip()
        return request.client.host if request.client else '127.0.0.1'
```

### Request Validation & Sanitization
```python
# File: backend/app/middleware/request_validation.py
import re
import logging
from fastapi import Request, HTTPException, status
from typing import Set

logger = logging.getLogger(__name__)

class RequestValidationMiddleware:
    """
    Request validation and sanitization middleware.
    """
    
    def __init__(self):
        # Common attack patterns
        self.sql_injection_patterns = [
            r"(\b(SELECT|INSERT|UPDATE|DELETE|DROP|CREATE|ALTER)\b)",
            r"(\b(UNION|OR|AND)\s+\d+\s*=\s*\d+)",
            r"(--|#|\/\*|\*\/)",
        ]
        
        self.xss_patterns = [
            r"<script[^>]*>.*?</script>",
            r"javascript:",
            r"on\w+\s*=",
            r"<iframe[^>]*>.*?</iframe>",
        ]
        
        self.path_traversal_patterns = [
            r"\.\./",
            r"\.\.\\",
            r"%2e%2e%2f",
            r"%2e%2e\\",
        ]
        
        # Compile patterns for performance
        self.compiled_patterns = {
            'sql': [re.compile(pattern, re.IGNORECASE) for pattern in self.sql_injection_patterns],
            'xss': [re.compile(pattern, re.IGNORECASE) for pattern in self.xss_patterns],
            'traversal': [re.compile(pattern, re.IGNORECASE) for pattern in self.path_traversal_patterns],
        }
    
    async def __call__(self, request: Request, call_next):
        # Validate request size
        if hasattr(request, 'headers'):
            content_length = request.headers.get('content-length')
            if content_length and int(content_length) > 10 * 1024 * 1024:  # 10MB limit
                raise HTTPException(
                    status_code=status.HTTP_413_REQUEST_ENTITY_TOO_LARGE,
                    detail="Request too large"
                )
        
        # Validate URL path
        if self._contains_malicious_patterns(request.url.path):
            logger.warning(f"Malicious pattern detected in path: {request.url.path}")
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Invalid request"
            )
        
        # Validate query parameters
        for key, value in request.query_params.items():
            if self._contains_malicious_patterns(f"{key}={value}"):
                logger.warning(f"Malicious pattern detected in query: {key}={value}")
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="Invalid query parameters"
                )
        
        return await call_next(request)
    
    def _contains_malicious_patterns(self, text: str) -> bool:
        """Check if text contains malicious patterns."""
        for pattern_type, patterns in self.compiled_patterns.items():
            for pattern in patterns:
                if pattern.search(text):
                    return True
        return False
```

## 5. Rate Limit Monitoring & Analytics

```python
# File: backend/app/services/rate_limit_analytics.py
import logging
from datetime import datetime, timedelta
from sqlalchemy.orm import Session
from sqlalchemy import func
from typing import Dict, List

from app.models.rate_limit_log import RateLimitLog, ViolationType

logger = logging.getLogger(__name__)

class RateLimitAnalytics:
    """
    Analytics and monitoring for rate limiting.
    """
    
    def __init__(self, db: Session):
        self.db = db
    
    def log_violation(self, ip_address: str, user_id: str, endpoint: str, 
                     violation_type: ViolationType, limit: int, actual: int):
        """Log rate limit violation."""
        violation = RateLimitLog(
            ip_address=ip_address,
            user_id=user_id,
            endpoint=endpoint,
            violation_type=violation_type,
            limit_value=limit,
            actual_value=actual,
            timestamp=datetime.utcnow()
        )
        self.db.add(violation)
        self.db.commit()
    
    def get_violation_stats(self, hours: int = 24) -> Dict:
        """Get rate limit violation statistics."""
        since = datetime.utcnow() - timedelta(hours=hours)
        
        violations = self.db.query(RateLimitLog).filter(
            RateLimitLog.timestamp >= since
        ).all()
        
        stats = {
            'total_violations': len(violations),
            'unique_ips': len(set(v.ip_address for v in violations)),
            'unique_users': len(set(v.user_id for v in violations if v.user_id)),
            'top_endpoints': self._get_top_violated_endpoints(violations),
            'violation_timeline': self._get_violation_timeline(violations)
        }
        
        return stats
    
    def _get_top_violated_endpoints(self, violations: List[RateLimitLog]) -> List[Dict]:
        """Get most frequently violated endpoints."""
        endpoint_counts = {}
        for violation in violations:
            endpoint_counts[violation.endpoint] = endpoint_counts.get(violation.endpoint, 0) + 1
        
        return [
            {'endpoint': endpoint, 'violations': count}
            for endpoint, count in sorted(endpoint_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        ]
    
    def _get_violation_timeline(self, violations: List[RateLimitLog]) -> List[Dict]:
        """Get violation timeline by hour."""
        timeline = {}
        for violation in violations:
            hour = violation.timestamp.replace(minute=0, second=0, microsecond=0)
            timeline[hour] = timeline.get(hour, 0) + 1
        
        return [
            {'hour': hour.isoformat(), 'violations': count}
            for hour, count in sorted(timeline.items())
        ]
```

## 6. Rate Limit Data Models

```python
# File: backend/app/models/rate_limit_log.py
from sqlalchemy import Column, String, Integer, DateTime, Enum, ForeignKey
from sqlalchemy.orm import relationship
from app.models.base import Base, BaseMixin
import enum

class ViolationType(str, enum.Enum):
    USER_RATE_LIMIT = "USER_RATE_LIMIT"
    IP_RATE_LIMIT = "IP_RATE_LIMIT"
    ENDPOINT_RATE_LIMIT = "ENDPOINT_RATE_LIMIT"
    DDOS_PROTECTION = "DDOS_PROTECTION"
    MALICIOUS_REQUEST = "MALICIOUS_REQUEST"

class RateLimitLog(Base, BaseMixin):
    __tablename__ = 'rate_limit_logs'
    
    ip_address = Column(String(45), nullable=False)  # IPv6 compatible
    user_id = Column(ForeignKey('users.id'), nullable=True)
    endpoint = Column(String(255), nullable=False)
    violation_type = Column(Enum(ViolationType), nullable=False)
    limit_value = Column(Integer, nullable=False)
    actual_value = Column(Integer, nullable=False)
    timestamp = Column(DateTime, nullable=False)
    
    user = relationship('User', back_populates='rate_limit_logs')
```

## 7. Integration with FastAPI Application

```python
# File: backend/app/main.py (modifications)
from app.middleware.rate_limiting import RateLimitMiddleware
from app.middleware.ddos_protection import DDoSProtectionMiddleware
from app.middleware.request_validation import RequestValidationMiddleware

app = FastAPI(title="MartechEngine API")

# Add security middleware (order matters!)
app.add_middleware(RequestValidationMiddleware)
app.add_middleware(DDoSProtectionMiddleware)
app.add_middleware(RateLimitMiddleware)
```

## 8. Configuration Updates

```python
# File: backend/app/core/config.py (additions)
class Settings(BaseSettings):
    # ... existing settings ...
    
    # Rate Limiting Configuration
    RATE_LIMITING_ENABLED: bool = True
    DDOS_PROTECTION_ENABLED: bool = True
    REQUEST_VALIDATION_ENABLED: bool = True
    
    # Redis Configuration for Rate Limiting
    REDIS_HOST: str = "localhost"
    REDIS_PORT: int = 6379
    REDIS_PASSWORD: Optional[str] = None
    
    # Rate Limiting Thresholds
    MAX_REQUEST_SIZE: int = 10 * 1024 * 1024  # 10MB
    DDOS_BLOCK_DURATION: int = 300  # 5 minutes
```

## 9. Monitoring & Alerting

```python
# File: backend/app/api/v1/endpoints/admin/rate_limits.py
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from app.core.database import get_db
from app.services.rate_limit_analytics import RateLimitAnalytics
from app.api.v1.dependencies.auth_deps import require_admin

router = APIRouter()

@router.get("/rate-limit-stats")
async def get_rate_limit_stats(
    hours: int = 24,
    db: Session = Depends(get_db),
    current_user = Depends(require_admin)
):
    """Get rate limiting statistics (admin only)."""
    analytics = RateLimitAnalytics(db)
    return analytics.get_violation_stats(hours)

@router.post("/block-ip")
async def block_ip(
    ip_address: str,
    duration: int = 3600,
    current_user = Depends(require_admin)
):
    """Manually block an IP address (admin only)."""
    # Implementation for manual IP blocking
    pass
```

## 10. Testing Strategy

```python
# File: backend/tests/test_rate_limiting.py
import pytest
import time
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

def test_rate_limiting_per_user():
    """Test user-specific rate limiting."""
    # Login and get token
    login_response = client.post("/api/v1/auth/login", json={
        "email": "test@example.com",
        "password": "password"
    })
    token = login_response.json()["access_token"]
    headers = {"Authorization": f"Bearer {token}"}
    
    # Make requests up to limit
    for i in range(30):  # Free tier limit
        response = client.get("/api/v1/projects", headers=headers)
        assert response.status_code == 200
    
    # Next request should be rate limited
    response = client.get("/api/v1/projects", headers=headers)
    assert response.status_code == 429
    assert "X-RateLimit-Limit" in response.headers

def test_ddos_protection():
    """Test DDoS protection mechanisms."""
    # Simulate rapid requests
    for i in range(150):  # Above DDoS threshold
        response = client.get("/api/v1/health")
        if response.status_code == 429:
            break
    
    assert response.status_code == 429
```

## 11. Next Steps

This comprehensive rate limiting and API protection system provides:
- ✅ **Multi-tier rate limiting** based on subscription plans
- ✅ **DDoS protection** with pattern detection
- ✅ **Request validation** against common attacks
- ✅ **Real-time monitoring** and analytics
- ✅ **Graceful error handling** with proper headers

**Next File**: Create the Asset Storage Service architecture to handle file uploads and generated content storage.
