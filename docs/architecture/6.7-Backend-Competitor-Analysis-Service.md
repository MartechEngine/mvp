Phase: 6 - Content & Analysis Suite
Part: 6.7
Title: Enterprise Competitor Analysis Service
Depends On: 6.6-Backend-Backlink-Analysis-Service.md
Objective: To implement the EnterpriseCompetitorAnalysisService, a sophisticated service that analyzes and synthesizes competitor data stored in the CentralRawData bank to identify strategic keyword gaps and provide a high-level overview of the competitive landscape.
1. Core Principles: Synthesizing Intelligence
Memory-First Synthesis: This service reads from multiple data types within the CentralRawData bank (e.g., the project's own keywords and competitor keywords) to create a holistic view.
AI-Powered Summarization (Credit Cost): The service leverages the UnifiedAIService to provide a qualitative "Executive Summary" of the competitive landscape. This is a value-added, credit-consuming operation.
Actionable Output: The primary output is a list of keyword gapsâ€”valuable keywords that competitors rank for but the user's project does not.
2. Competitor Analysis Pydantic Schemas
File Location: backend/app/schemas/competitor_analysis_schemas.py
File Content:
from pydantic import BaseModel, Field, ConfigDict
from typing import List, Optional

class CompetitorProfile(BaseModel):
    domain: str
    domain_rank: Optional[int]
    total_backlinks: Optional[int]
    referring_domains: Optional[int]

class KeywordGap(BaseModel):
    keyword: str
    competitor_domain: str
    search_volume: Optional[int]
    difficulty: Optional[int]

class CompetitorAnalysisResponse(BaseModel):
    project_id: str
    ai_executive_summary: str
    competitor_profiles: List[CompetitorProfile]
    top_keyword_gaps: List[KeywordGap]
    
    model_config = ConfigDict(from_attributes=True)

3. EnterpriseCompetitorAnalysisService Implementation
File Location: backend/app/services/competitor_analysis_service.py
File Content:
import logging
import asyncio
from sqlalchemy.orm import Session
from datetime import datetime

from app.services.unified_ai_service import EnterpriseUnifiedAIService, AITaskRequest
from app.schemas.ai_service_schemas import PromptTask
from app.services.project_memory_service import ProjectMemoryService
from app.schemas.competitor_analysis_schemas import CompetitorAnalysisResponse, CompetitorProfile, KeywordGap
from app.models.central_raw_data import CentralRawData
from app.models.project import Project

logger = logging.getLogger(__name__)

COMPETITOR_ANALYSIS_COST = 10 # Flat credit cost for the AI summary

class EnterpriseCompetitorAnalysisService:
    """
    Synthesizes competitor data from the CentralRawData bank into actionable intelligence.
    """

    def __init__(self, db: Session):
        self.db = db
        self.ai_service = EnterpriseUnifiedAIService(db)

    async def analyze_competitors_for_project(
        self, user_id: str, organization_id: str, project_id: str
    ) -> CompetitorAnalysisResponse:
        """
        Main entry point for competitor analysis.
        """
        project = self.db.query(Project).filter_by(id=project_id, organization_id=organization_id).one()
        
        # In a real implementation, you would fetch a list of competitors first.
        # For this example, we'll assume a competitor list and fetch their data.
        competitor_domains = ["competitor1.com", "competitor2.com"] # Placeholder
        
        # 1. Fetch all necessary data from the data bank concurrently
        tasks = [
            self._get_raw_data(project.url, 'KEYWORDS_DATAFORSEO'),
            self._get_raw_data(competitor_domains[0], 'KEYWORDS_DATAFORSEO'),
            self._get_raw_data(competitor_domains[1], 'KEYWORDS_DATAFORSEO'),
        ]
        results = await asyncio.gather(*tasks)
        
        own_keywords_raw, competitor1_keywords_raw, competitor2_keywords_raw = results
        
        if not own_keywords_raw:
             raise ValueError("No keyword data found for the project. Run a DCS scan first.")

        # 2. Process data to identify keyword gaps
        own_keywords = {kw['keyword'].lower() for kw in own_keywords_raw['tasks'][0].get('result', [])}
        
        all_gaps = {}
        for competitor_raw in [competitor1_keywords_raw, competitor2_keywords_raw]:
            if competitor_raw:
                competitor_domain = competitor_raw['tasks'][0].get('result', [{}])[0].get('target')
                for kw_data in competitor_raw['tasks'][0].get('result', []):
                    keyword = kw_data.get('keyword').lower()
                    if keyword not in own_keywords and keyword not in all_gaps:
                        all_gaps[keyword] = {"competitor_domain": competitor_domain, "search_volume": kw_data.get('sv')}

        top_keyword_gaps = [KeywordGap(keyword=kw, **data) for kw, data in list(all_gaps.items())[:50]]

        # 3. Prepare and execute the AI task for a qualitative summary
        ai_task = AITaskRequest(
            task=PromptTask.ANALYZE_COMPETITIVE_LANDSCAPE_V1,
            context={
                "project_url": project.url,
                "competitor_domains": competitor_domains,
                "keyword_gaps": [g.model_dump() for g in top_keyword_gaps]
            },
            user_id=user_id,
            organization_id=organization_id,
            project_id=project_id,
            estimated_credit_cost=COMPETITOR_ANALYSIS_COST
        )
        ai_response = await self.ai_service.execute_ai_task(ai_task)

        if not ai_response.success or not ai_response.data:
            raise Exception(f"AI competitor analysis failed: {ai_response.error}")

        # 4. Structure the final response
        response = CompetitorAnalysisResponse(
            project_id=project_id,
            ai_executive_summary=ai_response.data.get('executive_summary', 'Analysis complete.'),
            competitor_profiles=[], # Populate with summary data
            top_keyword_gaps=top_keyword_gaps
        )
        return response

    async def _get_raw_data(self, domain: str, data_type: str) -> dict | None:
        """Helper to fetch a single raw data record."""
        record = self.db.query(CentralRawData).filter_by(
            domain=domain, data_type=data_type
        ).order_by(CentralRawData.created_at.desc()).first()
        return record.raw_data if record else None

4. Next Steps
This file concludes the implementation of the core analysis services. We have now defined all the backend logic for transforming raw scan data into valuable, actionable intelligence for our users.
Next File: 6.8-Backend-Intelligence-API.md will create the FastAPI router to expose these now-robust analysis services (Keyword, Backlink, Competitor) to the frontend.