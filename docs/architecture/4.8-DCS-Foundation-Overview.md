Phase: 5 - DCS Engine & Scan Results
Part: 4.8
Title: DCS Foundation - High-Level Architecture
Depends On: 4.7-Frontend-Billing-History-UI.md
Objective: To provide a high-level architectural blueprint for the Data-driven Competitive Storytelling (DCS) Foundation. This document translates the product vision from core-app-idea.md and the chunk files into a production-ready, scalable, and secure server-side architecture.
1. Core Principles from Product Vision
This architecture is the direct engineering implementation of the product vision. The key principles are:
Three-Tier Data Architecture: The system is built around the three tiers of data: the Central Raw Data Bank (global cache), Project Memory (project-specific intelligence), and the RAG Foundation (future vector store). This is the cornerstone of the entire platform.
Zero Duplicate API Calls: The architecture is designed to enforce this rule. The Central Raw Data Bank is the first stop for any data request, eliminating redundant calls to costly third-party APIs like DataForSEO.
Asynchronous & Resilient by Default: All heavy-lifting (scans, analysis) is offloaded to background workers. The system is designed with a fallback chain (DataForSEO -> Custom Crawler -> Vertex AI Estimate) to ensure it is resilient to partial or full provider outages, as described in chunk-3.
Credit-Aware Operations: Every action that incurs a cost (API calls, AI analysis) is tightly integrated with the CreditService, ensuring users are billed accurately and transparently.
2. System Architecture Diagram
This diagram illustrates the cloud-native, event-driven architecture that is highly decoupled and scalable. It shows how a user's request to start a scan triggers a complex, resilient workflow.
graph TD
    subgraph "User Interaction"
        A[API Endpoint <br> POST /dcs/{projectId}/scan]
    end

    subgraph "Orchestration & Business Logic"
        B[DCS Orchestration Engine <br> (Celery Workflow)]
        C[Credit Service]
        D[Project Memory Service]
    end

    subgraph "Data Collection Layer (External Clients & Fallbacks)"
        E[DataForSEO Client]
        F[Google PageSpeed Client]
        G[Custom Crawler Service]
        H[Vertex AI Client <br> (Analysis & Estimation)]
    end

    subgraph "Data Persistence Layer (Three-Tier Storage)"
        I[(PostgreSQL: Central Raw Data Bank)]
        J[(PostgreSQL: Project Memory)]
        K[(Redis: Celery Queues & Caching)]
    end

    A -- "1. Dispatches Scan Task" --> B
    B -- "2. Reserve Credits" --> C
    B -- "3. Check for Cached Data" --> I
    B -- "4. Orchestrates Data Collection" --> E & F & G & H
    E & F & G & H -- "5. Return Raw Data" --> B
    B -- "6. Store Raw Data" --> I
    B -- "7. Process & Analyze" --> H
    H -- "8. Return Insights" --> B
    B -- "9. Store Insights" --> J
    B -- "10. Consume Credits" --> C
    
    B -- "Uses for Task Queues" --> K

3. Workflow Explanation
Initiation: The user hits a simple API endpoint (A) to start a scan. The API's only job is to create an Audit record and dispatch a Celery task to the DCS Orchestration Engine (B).
Credit Reservation: The Orchestrator's first step is to call the Credit Service (C) to reserve the estimated credits for the scan. If the user has insufficient funds, the task fails immediately.
Cache Check: The Orchestrator checks the Central Raw Data Bank (I) for fresh, existing data for the target domain to avoid API calls.
Data Collection: For any missing data, the Orchestrator calls the necessary clients (E, F). If a primary client (like DataForSEO) fails, it activates the fallback chain, using the Custom Crawler (G) and finally the Vertex AI Client (H) for estimation, as per the resilience strategy.
Store Raw Data: All newly fetched raw data is saved to the Central Raw Data Bank (I) with a checksum, making it available for all future scans across the platform.
Analysis: The collected data is passed to the Vertex AI Client (H) to calculate the AI Citation Score and generate qualitative summaries.
Store Insights: The final, processed insights (DCS Score, AI Score, recommendations, etc.) are saved to the project-specific Project Memory (J) by the Project Memory Service (D).
Credit Consumption: The Orchestrator calls the Credit Service (C) again to convert the credit reservation into a final transaction, consuming the credits. The final cost may be adjusted based on which data sources (and fallbacks) were used.
Completion: The Audit record is marked as COMPLETED, and a real-time event is sent to the frontend to update the UI.
4. Next Steps
With the high-level architecture for the DCS Foundation now defined, we can proceed to build its components, starting with the foundational data models that will store all the collected intelligence.
Next File: 5.1-Data-Models-DCS-and-Memory.md will implement the expanded, normalized SQLAlchemy models for the Three-Tier Data Architecture.
