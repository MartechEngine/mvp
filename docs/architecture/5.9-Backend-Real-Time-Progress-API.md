Phase: 5 - DCS Engine & Scan Results
Part: 5.9
Title: Backend Real-Time Progress API (SSE)
Depends On: 5.8-Backend-DCS-Orchestration-Engine.md
Objective: To design and implement a real-time communication layer using Server-Sent Events (SSE) to push live progress updates from the DCS Orchestration Engine to the frontend. This provides the user with a responsive and engaging experience during a scan.
1. Core Principle: One-Way, Server-Push Communication
For sending progress updates, we only need one-way communication from the server to the client. WebSockets, which are bidirectional, would be overkill. Server-Sent Events (SSE) is a simpler, more efficient web standard designed specifically for this use case. The connection is a standard HTTP connection, making it easier to manage and proxy.
2. Architectural Diagram
The architecture uses Redis Pub/Sub as a high-speed, non-blocking message broker between the Celery worker and the API server.

graph TD
    subgraph "Async Worker Process"
        A[DCS Celery Task] -- "1. Publishes status update" --> B((Redis Pub/Sub Channel));
    end

    subgraph "API Server Process"
        B -- "2. Subscribes to channel" --> C[SSE API Endpoint <br> GET /dcs/scans/{audit_id}/stream];
    end

    subgraph "User's Browser"
        C -- "3. Streams event data" --> D[Frontend Client (EventSource)];
    end

3. RedisPublisher Utility
We need a simple utility for our Celery task to publish updates.
File Location: backend/app/core/redis_publisher.py
File Content:
import redis
import json
from typing import Dict, Any

from app.core.config import settings

class RedisPublisher:
    """A utility for publishing real-time updates to Redis Pub/Sub."""
    def __init__(self):
        self.redis_client = redis.from_url(str(settings.REDIS_URL), decode_responses=True)

    def publish_progress(self, audit_id: str, progress: int, message: str, is_final: bool = False):
        """
        Publishes a progress update message to a specific audit channel.
        """
        channel = f"dcs_scan_progress:{audit_id}"
        payload = {
            "progress": progress,
            "message": message,
            "is_final": is_final
        }
        self.redis_client.publish(channel, json.dumps(payload))

    def close(self):
        self.redis_client.close()

4. Updating the Celery Orchestrator to Publish Updates
We modify the run_dcs_scan task to send progress updates at key stages.
File to Modify: backend/app/tasks/dcs_tasks.py
Content to Add/Modify:
# ... (imports)
from app.core.redis_publisher import RedisPublisher

# ... (inside run_dcs_scan task - CORRECTED SYNCHRONOUS VERSION)
@shared_task(bind=True, max_retries=3, default_retry_delay=300)
@sentry_trace("dcs_scan_orchestration")
def run_dcs_scan(self, audit_id: str):
    """
    Robust DCS scan orchestrator with guaranteed credit refunds on failure.
    Implements the full reserve/consume/refund lifecycle per overview.md Section 6.5 and 9.2.
    """
    db: Session = SessionLocal()
    publisher = RedisPublisher()
    reservation = None
    
    try:
        # ... (code to fetch audit, initialize services) ...
        
        publisher.publish_progress(audit_id, 10, "Initializing scan and reserving credits...")
        
        # ... (code for credit reservation) ...
        
        publisher.publish_progress(audit_id, 25, "Collecting performance data...")
        # Note: External API clients should be synchronous in Celery tasks
        perf_data = pagespeed_client.analyze_url_sync(audit.project.url)
        
        publisher.publish_progress(audit_id, 50, "Collecting SEO and backlink data...")
        seo_data = dataforseo_client.get_backlink_summary_sync(audit.project.url)
        
        publisher.publish_progress(audit_id, 75, "Performing AI analysis...")
        ai_analysis = vertexai_client.analyze_seo_data_sync(...)
        
        publisher.publish_progress(audit_id, 90, "Saving results to Project Memory...")
        # ... (code to save results) ...

        publisher.publish_progress(audit_id, 100, "Scan complete!", is_final=True)
        
        # ... (code to consume credits and commit) ...
        
    except Exception as exc:
        # ... (error handling logic) ...
        publisher.publish_progress(audit_id, 100, f"Scan failed: {str(exc)}", is_final=True)
    finally:
        publisher.close()
        db.close()

5. SSE API Endpoint Implementation
This endpoint will stream the updates from Redis to the connected client.
File Location: backend/app/api/v1/endpoints/dcs.py
File Content:
import asyncio
import json
from fastapi import APIRouter, Depends, Request
from sse_starlette.sse import EventSourceResponse
import redis.asyncio as redis

from app.core.config import settings
from app.api.v1.dependencies.auth_deps import get_current_active_user
# ... other imports from the new DCS API file

router = APIRouter(prefix="/dcs", tags=["DCS Scans"])

# ... (POST /scans/{project_id} endpoint) ...

@router.get(
    "/scans/{audit_id}/stream",
    summary="Stream live progress of a DCS Scan"
)
async def stream_scan_progress(
    audit_id: str,
    request: Request,
    current_user: UserModel = Depends(get_current_active_user)
):
    """
    This endpoint uses Server-Sent Events (SSE) to stream progress updates for a DCS scan.
    """
    # TODO: Add logic to verify that the current_user has access to this audit_id.

    async def event_generator():
        redis_client = redis.from_url(str(settings.REDIS_URL), decode_responses=True)
        pubsub = redis_client.pubsub()
        channel = f"dcs_scan_progress:{audit_id}"
        await pubsub.subscribe(channel)
        
        try:
            while True:
                # Check if the client has disconnected
                if await request.is_disconnected():
                    break

                message = await pubsub.get_message(ignore_subscribe_messages=True, timeout=10)
                if message:
                    data = json.loads(message['data'])
                    yield {"event": "progress_update", "data": json.dumps(data)}
                    if data.get("is_final"):
                        break
                
                # Yield a keep-alive comment to prevent connection closure
                yield {"event": "comment", "data": "keep-alive"}

        except asyncio.CancelledError:
            # Handle client disconnection
            pass
        finally:
            await pubsub.unsubscribe(channel)
            await redis_client.close()

    return EventSourceResponse(event_generator())

6. Next Steps
This file concludes the backend architecture for Phase 5. We have now designed all the components necessary to perform our core intelligence-gathering operations and provide real-time feedback to the user.
Next File: 5.10-Frontend-DCS-Scan-Results-UI.md