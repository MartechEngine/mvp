Phase: 6 - Content & Analysis Suite
Part: 6.5
Title: Enterprise Keyword Analysis Service
Depends On: 6.4-Backend-Content-Strategy-Service.md
Objective: To implement the EnterpriseKeywordAnalysisService, a sophisticated service that takes raw keyword data from the CentralRawData bank and enriches it with advanced, AI-powered insights. This includes semantic clustering, search intent classification, and opportunity scoring, transforming a simple list of keywords into a strategic asset.
1. Core Principles: Adding the Intelligence Layer
Memory-First, AI-Powered: This service reads keyword data already collected by the DCS, then applies a layer of deep analysis using our internal UnifiedAIService.
Free to View, Paid to Analyze: Viewing the raw keyword list from a scan is free. Running this advanced analysis is a value-added, credit-consuming service that provides significant strategic value.
Actionable Output: The goal is to produce actionable intelligence. The output is structured into semantic clusters and prioritized opportunities that directly inform the ContentStrategyService and ContentGenerationService.
2. Keyword Analysis Pydantic Schemas
File Location: backend/app/schemas/keyword_analysis_schemas.py
File Content:
from pydantic import BaseModel, Field, ConfigDict
from typing import List, Optional
from enum import Enum

class SearchIntent(str, Enum):
    INFORMATIONAL = "INFORMATIONAL"
    NAVIGATIONAL = "NAVIGATIONAL"
    COMMERCIAL = "COMMERCIAL"
    TRANSACTIONAL = "TRANSACTIONAL"

class KeywordAnalysis(BaseModel):
    """Detailed analysis for a single keyword.""" 
    keyword: str
    search_intent: SearchIntent
    relevance_score: float = Field(..., ge=0, le=1)
    search_volume: Optional[int]
    difficulty: Optional[int]

    model_config = ConfigDict(from_attributes=True)

class SemanticCluster(BaseModel):
    """A group of semantically related keywords."""
    cluster_name: str = Field(..., description="An AI-generated name for the topic cluster.")
    keywords: List[KeywordAnalysis]
    primary_intent: SearchIntent
    cluster_relevance_score: float = Field(..., ge=0, le=1)
    suggested_content_type: str = Field(..., description="e.g., Blog Post, Landing Page, Guide")

    model_config = ConfigDict(from_attributes=True)

class KeywordAnalysisResponse(BaseModel):
    """The full, structured response from the keyword analysis service."""
    project_id: str
    analysis_summary: str = Field(..., description="An AI-generated executive summary of the keyword landscape.")
    semantic_clusters: List[SemanticCluster]

3. EnterpriseKeywordAnalysisService Implementation
File Location: backend/app/services/keyword_analysis_service.py
File Content:
import logging
from sqlalchemy.orm import Session
from typing import List

from app.services.unified_ai_service import EnterpriseUnifiedAIService, AITaskRequest
from app.schemas.ai_service_schemas import PromptTask
from app.services.project_memory_service import ProjectMemoryService
from app.schemas.keyword_analysis_schemas import KeywordAnalysisResponse
from app.models.central_raw_data import CentralRawData
from app.models.project import Project

logger = logging.getLogger(__name__)

# Define a cost, e.g., 5 credits per 100 keywords analyzed
KEYWORD_ANALYSIS_COST_PER_100_KEYWORDS = 5

class EnterpriseKeywordAnalysisService:
    """
    Performs advanced AI-powered analysis on existing keyword data.
    """

    def __init__(self, db: Session):
        self.db = db
        self.ai_service = EnterpriseUnifiedAIService(db)
        self.memory_service = ProjectMemoryService(db)

    async def analyze_keywords_for_project(
        self,
        project_id: str,
        user_id: str,
        organization_id: str
    ) -> KeywordAnalysisResponse:
        """
        Main entry point for keyword analysis.
        """
        project = self.db.query(Project).filter_by(id=project_id, organization_id=organization_id).one()
        
        # 1. Fetch raw keyword data from the Central Raw Data bank
        raw_keyword_data_record = self.db.query(CentralRawData).filter_by(
            domain=project.url, data_type='KEYWORDS_DATAFORSEO'
        ).order_by(CentralRawData.created_at.desc()).first()

        if not raw_keyword_data_record or not raw_keyword_data_record.raw_data.get('tasks'):
            raise ValueError("No keyword data available for analysis. Please run a DCS scan first.")
        
        raw_keywords = raw_keyword_data_record.raw_data['tasks'][0].get('result', [])
        if not raw_keywords:
            raise ValueError("Keyword data is empty.")

        # 2. Calculate the credit cost for the operation
        estimated_cost = self._calculate_cost(len(raw_keywords))

        # 3. Prepare and execute the AI task (delegates credit handling)
        ai_task = AITaskRequest(
            task=PromptTask.CLUSTER_KEYWORDS_V1,
            context={
                "keyword_list": raw_keywords,
                "project_context": {"name": project.name, "url": project.url}
            },
            user_id=user_id,
            organization_id=organization_id,
            project_id=project_id,
            estimated_credit_cost=estimated_cost
        )
        ai_response = await self.ai_service.execute_ai_task(ai_task)

        if not ai_response.success or not ai_response.data:
            raise Exception(f"AI keyword analysis failed: {ai_response.error}")

        # 4. Structure the response
        analysis_response = KeywordAnalysisResponse(project_id=project_id, **ai_response.data)
        
        # 5. (Optional) Save the structured analysis back to Project Memory
        # self.memory_service.save_structured_data(
        #     project_id=project_id,
        #     category="KEYWORD_ANALYSIS",
        #     data=analysis_response.model_dump()
        # )
        
        logger.info(f"Keyword analysis for project {project_id} completed successfully.")
        return analysis_response

    def _calculate_cost(self, num_keywords: int) -> int:
        """Calculates the AI credit cost based on the number of keywords."""
        if num_keywords == 0:
            return 0
        # Calculate cost in blocks of 100
        cost = (num_keywords // 100 + 1) * KEYWORD_ANALYSIS_COST_PER_100_KEYWORDS
        return int(cost)

4. Next Steps
This service adds a deep layer of intelligence to our raw data. The next services will follow a similar pattern of reading from the central data bank, processing the information, and providing a structured, valuable output to the user.
Next File: 6.6-Backend-Backlink-Analysis-Service.md will create a service that enriches raw backlink data, transforming it from a simple list into an actionable profile of a website's authority.