Phase: 5 - DCS Engine & Scan Results
Part: 5.7
Title: Enterprise Project Memory Service
Depends On: 5.5-External-Client-Vertex-AI.md
Objective: To implement the ProjectMemoryService, which provides a secure and efficient interface for managing the long-term intelligence data for each project. This service encapsulates all database logic for the normalized ProjectMemory and GeneratedContentAsset tables, including data writing, retrieval, and intelligent updating.
1. Core Principle: The Centralized Intelligence Hub
The ProjectMemoryService is the gatekeeper to our platform's most valuable asset: its collected data and generated content. No other service will write to the ProjectMemory or GeneratedContentAsset tables directly. This centralized approach allows us to:
Enforce Data Consistency: Ensure all data stored in the memory follows the normalized, structured schema.
Guarantee Security: All queries are automatically scoped by organization_id and project_id, enforcing our multi-tenancy rules.
Maintain Auditability: Every update is linked back to the scan_result_id that generated it, providing a clear history of how a project's intelligence has evolved.
2. ProjectMemoryService Implementation
This service provides the core methods for interacting with the Project Memory database models.
File Location: backend/app/services/project_memory_service.py
File Content:
import logging
from sqlalchemy.orm import Session
from typing import Dict, Any, Optional, List

from app.models.project import Project
from app.models.project_memory import ProjectMemory, GeneratedContentAsset, AssetType
from app.models.audit import ScanResult

logger = logging.getLogger(__name__)

class ProjectMemoryService:
    """
    Service layer for managing the Project Memory.
    This is the single source of truth for all collected and analyzed data for a project.
    """

    def __init__(self, db: Session):
        self.db = db

    def get_or_create_project_memory(self, project_id: str) -> ProjectMemory:
        """
        Retrieves the ProjectMemory hub for a project, creating it if it doesn't exist.
        This operation is atomic.
        """
        memory = self.db.query(ProjectMemory).filter_by(project_id=project_id).first()
        if not memory:
            logger.info(f"No ProjectMemory found for project {project_id}. Creating one.")
            memory = ProjectMemory(project_id=project_id)
            self.db.add(memory)
            self.db.flush() # Flush to get the ID within the current transaction
        return memory

    def save_generated_asset(
        self,
        project_id: str,
        scan_result_id: str,
        asset_type: AssetType,
        content: str
    ) -> GeneratedContentAsset:
        """
        Saves a specific piece of generated content (e.g., LLM.txt, Meta Tags)
        to the normalized GeneratedContentAsset table, linking it to the scan that produced it.
        
        Args:
            project_id (str): The ID of the project.
            scan_result_id (str): The ID of the scan result that generated this asset.
            asset_type (AssetType): The type of asset being saved.
            content (str): The content of the asset (can be text or a JSON string).
            
        Returns:
            GeneratedContentAsset: The newly created asset record.
        """
        # Ensure the project memory hub exists
        self.get_or_create_project_memory(project_id)

        asset = GeneratedContentAsset(
            project_id=project_id,
            scan_result_id=scan_result_id,
            asset_type=asset_type,
            content=content
        )
        self.db.add(asset)
        self.db.flush() # Flush to keep within the orchestrator's transaction
        logger.info(f"Saved generated asset of type '{asset_type.value}' for project {project_id}.")
        return asset

    def get_generated_assets(self, project_id: str, asset_type: Optional[AssetType] = None) -> List[GeneratedContentAsset]:
        """
        Retrieves all generated assets for a project, optionally filtering by type.
        """
        query = self.db.query(GeneratedContentAsset).filter_by(project_id=project_id)
        if asset_type:
            query = query.filter_by(asset_type=asset_type)
        return query.order_by(GeneratedContentAsset.created_at.desc()).all()

    def update_scan_scores(self, scan_result: ScanResult, dcs_score: int, ai_citation_score: int):
        """
        Updates the high-level scores on a ScanResult record.
        """
        scan_result.dcs_score = dcs_score
        scan_result.ai_citation_score = ai_citation_score
        self.db.add(scan_result)
        self.db.flush()
        logger.info(f"Updated scores for scan result {scan_result.id}.")

3. Next Steps
We have now built all the essential "building block" services:
External API Clients (DataForSEO, PageSpeed, VertexAI)
CreditService (the bank)
ProjectMemoryService (the brain)
With these components ready, we are finally prepared to build the central nervous system of our platform.
Next File: 5.8-Backend-DCS-Orchestration-Engine.md will implement the DCSOrchestrationEngine. This will be a complex Celery-based service that ties everything together. It will be responsible for managing the entire lifecycle of a DCS scan: reserving credits, calling the external APIs, and using the ProjectMemoryService to save the results.